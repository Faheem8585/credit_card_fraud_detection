# Credit Card Fraud Detection System

## Project Overview

This project implements a production-ready credit card fraud detection system using machine learning. The system achieves 97.66% AUC score on real-world transaction data and provides a complete full-stack application with authentication, database persistence, and an intuitive web interface.

### Key Achievements
- **97.66% AUC Score**: State-of-the-art performance on 284,807 real transactions
- **Multi-Model Ensemble**: Combines Logistic Regression, Random Forest, Gradient Boosting, and Isolation Forest
- **Full-Stack Architecture**: FastAPI backend + Streamlit frontend + PostgreSQL database
- **Production-Ready**: Docker deployment, JWT authentication, comprehensive monitoring

## Technical Stack

### Machine Learning
- **Algorithms**: Ensemble of 4 models (LR, RF, GB, Isolation Forest)
- **Data**: 284,807 transactions from Kaggle Credit Card Fraud dataset
- **Preprocessing**: StandardScaler, SMOTE for class imbalance
- **Evaluation**: ROC-AUC, Precision-Recall, Confusion Matrix

### Backend
- **Framework**: FastAPI 0.104+
- **Authentication**: JWT with bcrypt password hashing
- **Database**: SQLAlchemy ORM (SQLite/PostgreSQL)
- **API Documentation**: Auto-generated OpenAPI/Swagger

### Frontend
- **Framework**: Streamlit 1.28+
- **Features**: Login/Signup, Real-time predictions, Admin dashboard
- **Visualizations**: Matplotlib, Seaborn, interactive charts

### DevOps
- **Containerization**: Docker + Docker Compose
- **Database**: PostgreSQL 13+ (or SQLite for development)
- **Python**: 3.9+

## Installation & Setup

### Local Development

1. **Clone and setup**
```bash
git clone <your-repo-url>
cd credit-card-fraud-detection
pip install -r requirements.txt
```

2. **Prepare data**
- Download the [Kaggle Credit Card Fraud dataset](https://www.kaggle.com/mlg-ulb/creditcardfraud)
- Place `creditcard.csv` in `/data/`

3. **Train models (optional)**
```bash
python src/preprocessing.py
python src/train_ensemble.py
```

4. **Run application**
```bash
# Terminal 1: API
python api/app.py

# Terminal 2: Dashboard
streamlit run dashboard/app.py
```

5. **Access**
- Dashboard: http://localhost:8501
- API Docs: http://localhost:8000/docs

### Docker Deployment

```bash
docker-compose up -d
```

Access dashboard at http://localhost:8501

## Project Structure

```
â”œâ”€â”€ api/                    # FastAPI backend
â”‚   â””â”€â”€ app.py             # Main API application
â”œâ”€â”€ auth/                  # Authentication module
â”‚   â””â”€â”€ auth.py           # JWT implementation
â”œâ”€â”€ dashboard/             # Streamlit frontend
â”‚   â”œâ”€â”€ app.py            # Main dashboard
â”‚   â””â”€â”€ assets/           # Visualizations
â”œâ”€â”€ database/              # Database layer
â”‚   â”œâ”€â”€ db.py             # SQLAlchemy models
â”‚   â”œâ”€â”€ crud.py           # CRUD operations
â”‚   â””â”€â”€ schema.sql        # PostgreSQL schema
â”œâ”€â”€ data/                  # Datasets
â”‚   â”œâ”€â”€ creditcard.csv    # Raw Kaggle data
â”‚   â””â”€â”€ processed/        # Preprocessed data
â”œâ”€â”€ models/                # Trained models
â”‚   â”œâ”€â”€ lr_model.pkl
â”‚   â”œâ”€â”€ rf_model.pkl
â”‚   â”œâ”€â”€ gb_model.pkl
â”‚   â”œâ”€â”€ iso_forest_model.pkl
â”‚   â””â”€â”€ ensemble_config.json
â”œâ”€â”€ src/                   # Source code
â”‚   â”œâ”€â”€ preprocessing.py   # Data preparation
â”‚   â””â”€â”€ train_ensemble.py  # Model training
â”œâ”€â”€ docker-compose.yml     # Docker orchestration
â”œâ”€â”€ Dockerfile.api         # API container
â”œâ”€â”€ Dockerfile.dashboard   # Dashboard container
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md             # This file
```

## Usage Guide

### Creating an Account

1. Navigate to http://localhost:8501
2. Click "Signup" in sidebar
3. Enter email and password
4. You'll be logged in automatically

### Making Predictions

**Via Web Interface:**
1. Login to dashboard
2. Go to "Fraud Detection" page
3. Enter transaction details
4. Click "Analyze Transaction"

**Via API:**
```python
import requests

# 1. Get authentication token
response = requests.post(
    "http://localhost:8000/auth/signup",
    json={"email": "user@example.com", "password": "securepass"}
)
token = response.json()["access_token"]

# 2. Make prediction
headers = {"Authorization": f"Bearer {token}"}
transaction = {
    "Time": 100, "Amount": 500.0,
    "V1": 0.1, "V2": -0.5, ..., "V28": 0.3
}
prediction = requests.post(
    "http://localhost:8000/predict",
    headers=headers,
    json=transaction
)
print(prediction.json())
```

### Admin Dashboard

Access system-wide statistics:
- Email: `admin2@fraud.com`
- Password: `admin123`

Features:
- Total transactions and users
- System fraud rate
- Blocked transactions
- Pending alerts

## Model Performance

| Model | AUC Score | Notes |
|-------|-----------|-------|
| Gradient Boosting ğŸ† | 0.9766 | Best performer |
| Logistic Regression | 0.9660 | Fast, interpretable |
| Random Forest | 0.9621 | Robust to outliers |
| Ensemble | 0.9668 | Weighted combination |
| Isolation Forest | 0.8254 | Anomaly detection |

**Dataset**: 284,807 transactions (0.17% fraud)

## API Reference

### Authentication Endpoints

**POST /auth/signup**
- Create new user account
- Body: `{"email": "string", "password": "string"}`
- Returns: JWT token

**POST /auth/login**
- Authenticate existing user
- Body: `{"email": "string", "password": "string"}`
- Returns: JWT token

**GET /auth/me**
- Get current user info
- Requires: Bearer token
- Returns: User details

### Prediction Endpoints

**POST /predict**
- Make fraud prediction
- Requires: Bearer token
- Body: Transaction with 30 features (Time, Amount, V1-V28)
- Returns: Fraud probability, decision, risk level

**GET /transactions**
- Get user's transaction history
- Requires: Bearer token
- Query params: `limit`, `offset`
- Returns: List of transactions

### Admin Endpoints

**GET /admin/stats**
- Get system statistics
- Requires: Admin role
- Returns: Total transactions, users, fraud rate

**GET /admin/alerts**
- Get pending fraud alerts
- Requires: Admin role
- Returns: List of high-risk transactions

## Configuration

### Environment Variables

Create `.env` file:

```bash
# Database URL
DATABASE_URL=sqlite:///./fraud_detection.db
# or for PostgreSQL:
# DATABASE_URL=postgresql://user:pass@localhost:5432/fraud_db

# JWT Secret (change in production!)
JWT_SECRET_KEY=your-super-secret-key-here

# API URL (for dashboard)
API_URL=http://localhost:8000
```

### Database Setup (PostgreSQL)

```bash
# Create database
createdb fraud_db

# Initialize schema
psql fraud_db < database/schema.sql

# Update DATABASE_URL in .env
```

## Development

### Training New Models

```bash
# 1. Update data (place new creditcard.csv in data/)
# 2. Preprocess
python src/preprocessing.py

# 3. Train ensemble
python src/train_ensemble.py

# This generates:
# - models/*.pkl (trained models)
# - dashboard/assets/*.png (visualizations)
# - models/ensemble_config.json (metrics)
```

### Running Tests

```bash
# Install test dependencies
pip install pytest pytest-cov

# Run tests
pytest tests/

# With coverage
pytest --cov=. tests/
```

## Security Considerations

- **Password Security**: bcrypt hashing with automatic salt
- **JWT Security**: 24-hour token expiration
- **SQL Injection**: Prevented by SQLAlchemy ORM
- **Role-Based Access**: User/Admin separation
- **HTTPS**: Configure reverse proxy (nginx/traefik) for production

## Performance

- **Prediction Latency**: < 100ms average
- **Throughput**: ~100 req/sec (single process)
- **Model Load Time**: ~2 seconds at startup
- **Database**: Indexed queries for fast lookups

## Troubleshooting

**Models not loading:**
- Ensure models are in `models/` directory
- Run `python src/train_ensemble.py` to generate models

**Database connection errors:**
- Check `DATABASE_URL` in environment
- Ensure PostgreSQL is running (if using Postgres)
- For SQLite, ensure write permissions

**Authentication failures:**
- Verify JWT_SECRET_KEY is set
- Check token expiration (24 hours)
- Clear browser cache and re-login

## Future Enhancements

- [ ] Real-time streaming predictions
- [ ] Advanced anomaly detection
- [ ] Email/SMS fraud alerts
- [ ] Historical trend analysis
- [ ] Model explainability (SHAP values)
- [ ] A/B testing framework
- [ ] Prometheus metrics export

## Contributing

This is a personal project, but suggestions are welcome! Feel free to open issues for bugs or feature requests.

## License

MIT License - see LICENSE file

## Acknowledgments

- **Dataset**: Kaggle Credit Card Fraud Detection dataset
- **Frameworks**: FastAPI, Streamlit, scikit-learn
- **Inspiration**: Real-world fraud detection systems in fintech

---

**Built with passion for machine learning and fraud detection** ğŸ›¡ï¸
